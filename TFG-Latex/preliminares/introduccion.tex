% !TeX root = ../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Introducción
%*******************************************************

% \manualmark
% \markboth{\textsc{Introducción}}{\textsc{Introducción}} 

\chapter{Introducción}

\indent Cuando enfrentamos un problema de optimización que depende de pocos factores, es sencillo idear estrategias para resolverlo y encontrar una solución. Sin embargo, a medida que crece el número de variables, la complejidad del problema aumenta, y se hace inviable resolverlo mediante métodos tradicionales. Para abordar esta problemática, se han diseñado algoritmos específicos para manejar la alta dimensionalidad utilizando metaheurísticas. Estas buscan optimizar la exploración del espacio de búsqueda, logrando un equilibrio entre exploración y explotación, lo que permite realizar búsquedas efectivas en un espacio donde la porción representada por la población de búsqueda es ínfima comparada con el espacio total. No obstante, estos algoritmos presentan limitaciones, y cuando el número de variables es suficientemente alto, hay dos opciones, por un lado, las metaheurísticas especialmente diseñado para LSGO, como SHADE-ILS, y por el otro, técnicas que permitan reducir la dimensionalidad que aborda el algoritmo.

En este trabajo, proponemos utilizar técnicas de \textbf{agrupamiento diferencial automático de variables}, que permite identificar las variables que interactúan entre sí, para asignarles el mismo grupo. De esta forma somos capaces de reducir el problema en subproblemas, uno para cada subgrupo ya que cada variable solo interactúa con las de su propio grupo y no (o mínimamente) con las de otros grupos. Así, podemos reducir la dimensión efectiva del problema, convirtiendo un problema de optimización de gran escala en problemas de optimización de menor tamaño. Nuestro objetivo es hibridar esta técnica con algoritmos diseñados para la alta dimensionalidad y con algoritmos que no están específicamente adaptados para ello. Compararemos el rendimiento aplicando y no aplicando esta técnica en ambos tipos de algoritmos.

Para probar la efectividad de esta técnica, se han planteado los siguientes objetivos:

\section{Objetivos}

\subsection*{Parte matemática}
\begin{itemize}
    \item \textbf{Análisis teórico}: Repaso de las técnicas matemáticas tradicionales en la literatura para resolver problemas de optimización sin restricciones.
    \item \textbf{Estudio de teoremas}: Exposición y análisis de los teoremas en los que se basa el agrupamiento diferencial.
    \item \textbf{Fundamentos estadísticos}: Explicación de los tests estadísticos utilizados para la comparación de algoritmos.
\end{itemize}

\subsection*{Parte informática}
\begin{itemize}
    \item \textbf{Desarrollo de una biblioteca de técnicas de agrupamiento}: Implementación de algoritmos para optimización continua sin restricciones en el lenguaje de programación Julia y de técnicas de agrupamiento automático de variables.
    \item \textbf{Selección de algoritmos}: Descripción de los algoritmos que se incluirán en la biblioteca y que se emplearán en las comparaciones.
    \item \textbf{Evaluación experimental}: Análisis de los algoritmos en el benchmark \textit{cec2013lsgo}, presentación de resultados y conclusiones obtenidas.
\end{itemize}

\section{Estructura de la memoria}

El trabajo se divide en tres partes claramente diferenciadas y cada parte está dividida en capítulos. Ademas de las dos partes que constituyen el contenido de este TFG, tenemos esta primera sección introductoria, donde se pone en contexto el trabajo, se definen los objetivos y se hace un repaso de la bibliografía necesaria. 
Además, se hace una estimación del presupuesto y del tiempo dedicado a cada tarea.

La parte Matemática está dividida en 3 capítulos, un primer capítulo donde se realizan definiciones importantes sobre optimización de funciones, se exponen algunos teoremas necesarios y se explican los métodos de búsqueda lineal y el algoritmo L-BFGS-B, que será un componente importante de nuestro algoritmo final. El segundo capítulo de esta sección se define el agrupamiento diferencial y se citan y demuestran los teoremas más importantes que justifican el diseño y utilidad de los algoritmos de agrupamiento automático de variables. Además se proporcionan algunas definiciones previas necesarias sobre separabilidad de funciones. Por último en la tercera sección de esta parte, se explican los fundamentos de los tests estadísticos y se definen los tests que suelen ser utilizados para comparar algoritmos. 

En la parte informática, tenemos un capitulo inicial donde se definen los componentes de los algoritmos que formarán nuestra propuesta, una segunda parte donde se explican los algoritmos que luego hibridaremos con el agrupamiento de variables. En tercer lugar se explicará nuestra propuesta: combinar ERDG con SHADE y SHADE-ILS. Por último, unas secciones finales donde se exponen los resultados obtenidos y las conclusiones que hemos obtenido de los resultados.

\chapter{Repaso Bibliográfico}

En esta sección, haremos un repaso bibliográfico sobre la optimización global a gran escala (LSGO, por sus siglas en inglés, \textit{Large Scale Global Optimization}). Se proporcionará un contexto general de las distintas técnicas metaheurísticas y enfoques que existen para abordar este tipo de problemas, y se situarán nuestros algoritmos en este contexto, explicando en mayor profundidad aquellas técnicas que están más relacionadas con los algoritmos \textit{SHADE} \cite{TanabeShade}, \textit{SHADE-ILS} \citep{Molina2018}, \textit{ERDG} \cite{ERDG} y \textit{DG2} \cite{DG2}. Para ello nos basaremos en el estudio realizado por \citeauthor{Review_I} en \cite{Review_I} y \cite{Review_II}.

\section{Enfoques Principales en LSGO}

A continuación, se presentan los enfoques principales en LSGO, los cuales se han desarrollado para afrontar la complejidad de los problemas de optimización de gran escala:

\begin{enumerate}
    \item \textbf{Descomposición del problema}: Dividir el problema en subproblemas manejables.
    \item \textbf{Hibridación y búsqueda local memética}: Combina algoritmos evolutivos con técnicas de búsqueda local.
    \item \textbf{Operadores de muestreo y variación}: Técnicas de muestreo para explorar el espacio de búsqueda.
    \item \textbf{Modelado por aproximación y uso de modelos sustitutos}: Se utilizan modelos simplificados para reducir el coste computacional.
    \item \textbf{Métodos de inicialización}: Métodos para asegurar una cobertura uniforme del espacio de búsqueda.
    \item \textbf{Paralelización}: Uso de múltiples instancias de algoritmos para acelerar la búsqueda.
\end{enumerate}

\section{Explotación de la Estructura del Problema (evitando la caja negra)}

Explotar la estructura del problema es común en diversas áreas de la optimización. La optimización de tipo \textit{gray-box} es un concepto relativamente nuevo que se centra en incorporar la estructura del problema en el proceso de optimización. Este enfoque busca descubrir y explorar un “orden oculto”, un concepto ampliamente estudiado en computación evolutiva en el contexto del aprendizaje de dependencias (\textit{linkage learning}). Las dependencias entre variables son cruciales para el rendimiento de los algoritmos genéticos (GAs). Sin conocer estas dependencias, incluso problemas separables pueden ser exponencialmente difíciles para GAs simples, y su resolución puede requerir tamaños de población exponencialmente grandes para encontrar el óptimo global.

En la optimización \textit{gray-box}, se asume que la estructura del problema es conocida \textit{a priori}, como ocurre en problemas discretos y combinatorios.

Sin embargo, en problemas continuos, la estructura puede no ser evidente, por lo que primero debe ser descubierta. Se han propuesto diversos algoritmos para analizar la interacción entre variables y capturar la topología del problema, lo cual no solo convierte problemas de tipo \textit{black-box} en \textit{gray-box}, sino que también permite revelar información no trivial, incluso en problemas completamente conocidos (\textit{white-box}).

La información estructural puede emplearse de diferentes formas para mejorar el rendimiento en la optimización. Algunos métodos, como la \textit{cooperative co-evolution} (CC) \cite{CC}, descomponen el problema en subproblemas de menor dimensionalidad, requiriendo un análisis de interacción de variables para lograr una descomposición adecuada. Otros métodos, como los algoritmos evolutivos basados en distribuciones (\textit{EDAs}) y los algoritmos de optimización bayesiana (\textit{BOAs}), no descomponen el problema explícitamente, pero capturan y aprovechan la información de interacción mediante modelos probabilísticos construidos durante el proceso de optimización.


Para descubrir la estructura interna del problema, existen dos aproximaciones, los métodos implícitos y los métodos explícitos. A continuación se presenta una clasificación de ambos métodos:

\begin{table}[H]
\renewcommand{\arraystretch}{1.5} % Ajusta la altura de las filas
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|p{12cm}|}
\hline
\textbf{Método} & \textbf{Descripción} \\ \hline

\textbf{Adaptación de Interacciones} & Métodos que extienden algoritmos genéticos (GAs) simples agregando mecanismos para mejorar la representación del problema y promover una vinculación estrecha (\textit{tight linkage}). \\ \hline

\textbf{Modelos Probabilísticos} & Métodos que utilizan distribuciones de probabilidad para representar la función objetivo o características del problema. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline

- \textit{Construcción de un modelo de interacción de variables} & Los \textit{EDAs} y \textit{BOAs} modelan las interacciones entre variables mediante redes bayesianas o matrices de covarianza adaptativas. Este enfoque captura patrones complejos en el problema. \\ \hline

- \textit{Construcción de un modelo de la función objetivo} & La optimización bayesiana construye un modelo probabilístico de la función objetivo basado en distribuciones previas y posteriores, que se actualizan con nuevas evaluaciones. \\ \hline

- \textit{Construcción de un modelo del movimiento poblacional} & Estrategias como \textit{CMA-ES} modelan el movimiento poblacional utilizando distribuciones gaussianas multivariantes, ajustando la matriz de covarianza para reflejar el paisaje del problema. \\ \hline

\textbf{Reducción Dimensional y Partición del Espacio} & Técnicas que reducen la dimensionalidad o dividen el espacio en subespacios más pequeños para simplificar la complejidad computacional en problemas de gran escala. Ejemplos incluyen proyecciones aleatorias y análisis de componentes principales (PCA). \\ \hline

\textbf{Distribuciones de Cola Pesada} & Uso de distribuciones como Lévy, Cauchy o t-distributions para mejorar la exploración y la diversidad poblacional. Estas distribuciones son útiles para evitar el estancamiento en óptimos locales. \\ \hline

\end{tabular}%
}
\caption{Resumen de métodos implícitos para la explotación de la estructura del problema en optimización.}
\label{tab:implicit_methods}
\end{table}

\begin{table}[H]
\renewcommand{\arraystretch}{1.5} % Ajusta la altura de las filas
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|p{12cm}|}
\hline
\textbf{Método} & \textbf{Descripción} \\ \hline

\textbf{Descomposición en Coevolución Cooperativa (CC)} & Divide el problema en subproblemas de menor dimensionalidad, optimizando cada uno por separado en un esquema de coevolución. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{CCGA (Cooperative Coevolution Genetic Algorithm)} & Divide un problema de $n$ dimensiones en $n$ subproblemas unidimensionales. Útil para problemas de baja interacción entre variables. \\ \hline
- \textit{Divide-in-half} & Divide el problema en dos subcomponentes de igual tamaño, optimizados iterativamente con estrategias como DE (\textit{Differential Evolution}). \\ \hline

\textbf{Gestión de Interacciones entre Variables} & Métodos que identifican relaciones entre variables para minimizar interacciones entre componentes. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{Agrupamiento Aleatorio (Random Grouping)} & Reorganiza aleatoriamente variables después de cada ciclo evolutivo para aumentar la probabilidad de agrupar variables relacionadas. \\ \hline
- \textit{Agrupamiento Delta (Delta Grouping)} & Ordena variables según sus desplazamientos medios entre iteraciones, agrupándolas por magnitud similar. \\ \hline
- \textit{Minimización de Diferencias de Fitness (DI)} & Reorganiza variables para minimizar diferencias en las interacciones detectadas, optimizando componentes uniformes. \\ \hline

\textbf{Métodos Estadísticos} & Inferencia de interacciones utilizando análisis estadístico de la población en evolución. \\ \hline

\textbf{Métodos Basados en Diferencias Finitas} & Utilizan diferencias finitas para detectar interacciones entre pares de variables. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{DG (Differential Grouping)} & Forma componentes no separables mediante un análisis iterativo de interacciones con menor coste computacional. \\ \hline

\textbf{Agrupamiento Automático y Semiautomático} & Algoritmos que forman grupos de forma automática o requieren que el usuario especifique el número/tamaño de los componentes. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{Automático} & Métodos como \textit{DG2} usan matrices de interacción y algoritmos de componentes conectados para agrupar. \\ \hline
- \textit{Semiautomático} & Requieren información adicional, como el número o tamaño de componentes, para formar grupos. \\ \hline
- \textit{k-s Dimensional Components} & Métodos que requieren que el usuario especifique tanto el número como el tamaño de los componentes para formar los grupos. \\ \hline
\end{tabular}%
}
\caption{Resumen de métodos explícitos para la explotación de la estructura del problema en optimización.}
\label{tab:explicit_methods}
\end{table}

Tras haber establecido una clasificación, podemos observar que DG2 y ERDG pertenecen a la categoría de algoritmos explícitos, basados en diferencias finitas y automáticos.

\section{Hibridación y Algoritmos Meméticos}

El teorema de No Free Lunch \cite{no_free_lunch} indica que ningún algoritmo de búsqueda puede superar consistentemente a todos los demás en todos los problemas posibles. La \textbf{hibridación} busca combinar las fortalezas de diferentes algoritmos para mejorar su rendimiento, la calidad de las soluciones y su integración en sistemas más amplios.

\begin{itemize}
\item \textit{Algoritmos de Búsqueda Local Híbrida:}
Estos algoritmos se basan únicamente en búsqueda local sin un componente global explícito. Por ejemplo, el \textit{Multiple Trajectory Search} (MTS) emplea tres métodos de búsqueda local, seleccionando el mejor para optimizar en vecindades específicas. Este enfoque ha demostrado eficacia en problemas de hasta 1000 dimensiones.

\item \textit{Algoritmos Meméticos:}
Integran búsqueda local dentro de un marco evolutivo global, balanceando exploración y explotación. Son populares en la optimización de gran escala, destacándose en competiciones de LSGO. Un ejemplo es el algoritmo SHADE-ILS, que utilizaremos en nuestra propuesta. Los principales aspectos de diseño incluyen:
\begin{itemize}
    \item \textbf{Frecuencia de búsqueda local:} Puede ser fija, adaptativa o probabilística.
    \item \textbf{Selección de soluciones:} Basada en rendimiento, aleatoriedad o todas las soluciones.
    \item \textbf{Intensidad de búsqueda:} Determina la duración de la búsqueda local, con enfoques fijos o adaptativos.
    \item \textbf{Procedimientos de búsqueda local:} Amplia variedad, incluyendo métodos como MTS-LS, L-BFGS-B.
\end{itemize}

\item \textit{Hibridación Coevolutiva}
Combina la descomposición de problemas con algoritmos meméticos. Los problemas se dividen en subproblemas optimizados con algoritmos globales seguidos de episodios de búsqueda local. 
\end{itemize}

\section{Operadores de Muestreo y Variación en DE y PSO}

Los operadores de muestreo y variación buscan mantener la diversidad en la población y mejorar la eficacia de los algoritmos en la exploración de grandes espacios de búsqueda. Dos enfoques comunes son:

\begin{itemize}

\item{Evolución Diferencial (DE)}

La Evolución Diferencial (DE) \cite{DE} es un algoritmo popular en la optimización global debido a su simplicidad y efectividad. Variantes como \textit{SHADE} y \textit{SHADE-ILS} han surgido como adaptaciones de DE para problemas de gran escala:
\begin{itemize}
    \item \textbf{SHADE}: Una variante de DE que ajusta adaptativamente el tamaño de la población y los parámetros de mutación para mantener la diversidad en poblaciones grandes.
    \item \textbf{SHADE-ILS}: Extiende SHADE mediante la integración de estrategias de búsqueda local, mejorando la precisión en problemas de alta dimensionalidad.
\end{itemize}

\item{Particle Swarm Optimization (PSO)}

PSO \cite{PSO} es un método basado en el comportamiento social de partículas. Aunque efectivo en problemas de baja dimensionalidad, enfrenta retos en alta dimensionalidad, para lo cual se han introducido estrategias de \textit{mantenimiento de diversidad} y \textit{re-inicialización}.

\end{itemize}

\begin{table}[H]
\renewcommand{\arraystretch}{1.5} % Ajusta la altura de las filas
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|p{12cm}|}
\hline
\textbf{Método} & \textbf{Descripción} \\ \hline

\textbf{Estrategias de mutación en DE} & Variaciones de la estrategia de mutación para mejorar la convergencia y diversidad en problemas de gran escala. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{Adaptación de estrategias de mutación} & Aplicación adaptativa de estrategias según el tipo de problema, como DE/rand/1 o DE/current-to-best/1. \\ \hline
- \textit{Selección de vectores} & Uso de vectores basados en calidad o cercanía, como la combinación de global-best y personal-best. \\ \hline

\textbf{Adaptación de parámetros en DE} & Ajuste dinámico de parámetros como el factor de escala ($F$) y la tasa de cruce ($CR$) para mejorar la exploración y explotación. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{Muestreo probabilístico} & Uso de distribuciones (uniforme, gaussiana, Cauchy) para generar parámetros adaptativos. \\ \hline
- \textit{Procesos caóticos} & Ajuste de $F$ y $CR$ mediante procesos caóticos para mejorar la búsqueda en espacios complejos. \\ \hline

\textbf{Mantenimiento de diversidad en DE} & Prevención de pérdida de diversidad en alta dimensionalidad mediante partición del espacio, coevolución o uso de archivos de soluciones. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{Multipoblación} & Subpoblaciones con estrategias independientes para promover exploración y explotación. \\ \hline
- \textit{Archivos externos} & Almacenamiento de soluciones descartadas o fallidas para diversificar el cruce y la mutación. \\ \hline

\textbf{Actualización de PSO} & Modificación de reglas de actualización para evitar convergencia prematura y mejorar la exploración en alta dimensionalidad. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{Reglas de actualización alternativas} & Reducción de la dependencia en global-best mediante aprendizajes sociales o mutaciones distribuidas. \\ \hline
- \textit{Topologías dinámicas} & Uso de vecindarios dinámicos o estructuras de multipoblación para mejorar la diversidad. \\ \hline

\textbf{Mantenimiento de diversidad en PSO} & Mecanismos para equilibrar la exploración y explotación en grandes dimensiones. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{Reinicialización parcial} & Reubicación de partículas en áreas de alta actividad para concentrar la búsqueda. \\ \hline
- \textit{Muestreo basado en oposición} & Exploración en espacios opuestos para aumentar las probabilidades de mejora. \\ \hline

\textbf{Partición del espacio en PSO} & División del espacio de búsqueda en subregiones optimizadas por separado para mejorar el enfoque y evitar estancamientos. \\ \hline
\multicolumn{2}{|l|}{\textbf{Submétodos:}} \\ \hline
- \textit{Agrupamiento de dimensiones} & Actualización segmentada de dimensiones para evitar convergencia prematura. \\ \hline
- \textit{Subenjambres} & Subenjambres independientes que comparten información de forma controlada para mantener la diversidad. \\ \hline

\end{tabular}%
}
\caption{Resumen de operadores de muestreo y variación en DE y PSO para optimización global a gran escala.}
\label{tab:sampling_variation}
\end{table}

Una vez terminada una exposición de donde se sitúan los algoritmos que vamos a utilizar, discutiremos sus propiedades teóricas y realizaremos un estudio comparativo para comprobar si el agrupamiento diferencial de variables es efectivo en todos los casos. Llegaremos a la conclusión de que no se puede aplicar directamente la descomposición de variables con cualquier algoritmo. Los resultados de SHADE-ILS, demuestran que en algoritmos pensados para al alta dimensionalidad, aplicar descomposición no necesariamente mejora los resultados obtenidos, y es necesario realizar mejoras en este algoritmo si se quiere utilizar con problemas descompuestos. Esto último, se deja como trabajo futuro.

\endinput
